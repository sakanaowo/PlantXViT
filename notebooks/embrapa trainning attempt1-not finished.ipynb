{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_FltkrgroqG",
        "outputId": "67a19f81-f3e3-4913-fd6c-c1500bed444b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PlantXViT'...\n",
            "remote: Enumerating objects: 50338, done.\u001b[K\n",
            "remote: Counting objects:   1% (1/67)\u001b[K\rremote: Counting objects:   2% (2/67)\u001b[K\rremote: Counting objects:   4% (3/67)\u001b[K\rremote: Counting objects:   5% (4/67)\u001b[K\rremote: Counting objects:   7% (5/67)\u001b[K\rremote: Counting objects:   8% (6/67)\u001b[K\rremote: Counting objects:  10% (7/67)\u001b[K\rremote: Counting objects:  11% (8/67)\u001b[K\rremote: Counting objects:  13% (9/67)\u001b[K\rremote: Counting objects:  14% (10/67)\u001b[K\rremote: Counting objects:  16% (11/67)\u001b[K\rremote: Counting objects:  17% (12/67)\u001b[K\rremote: Counting objects:  19% (13/67)\u001b[K\rremote: Counting objects:  20% (14/67)\u001b[K\rremote: Counting objects:  22% (15/67)\u001b[K\rremote: Counting objects:  23% (16/67)\u001b[K\rremote: Counting objects:  25% (17/67)\u001b[K\rremote: Counting objects:  26% (18/67)\u001b[K\rremote: Counting objects:  28% (19/67)\u001b[K\rremote: Counting objects:  29% (20/67)\u001b[K\rremote: Counting objects:  31% (21/67)\u001b[K\rremote: Counting objects:  32% (22/67)\u001b[K\rremote: Counting objects:  34% (23/67)\u001b[K\rremote: Counting objects:  35% (24/67)\u001b[K\rremote: Counting objects:  37% (25/67)\u001b[K\rremote: Counting objects:  38% (26/67)\u001b[K\rremote: Counting objects:  40% (27/67)\u001b[K\rremote: Counting objects:  41% (28/67)\u001b[K\rremote: Counting objects:  43% (29/67)\u001b[K\rremote: Counting objects:  44% (30/67)\u001b[K\rremote: Counting objects:  46% (31/67)\u001b[K\rremote: Counting objects:  47% (32/67)\u001b[K\rremote: Counting objects:  49% (33/67)\u001b[K\rremote: Counting objects:  50% (34/67)\u001b[K\rremote: Counting objects:  52% (35/67)\u001b[K\rremote: Counting objects:  53% (36/67)\u001b[K\rremote: Counting objects:  55% (37/67)\u001b[K\rremote: Counting objects:  56% (38/67)\u001b[K\rremote: Counting objects:  58% (39/67)\u001b[K\rremote: Counting objects:  59% (40/67)\u001b[K\rremote: Counting objects:  61% (41/67)\u001b[K\rremote: Counting objects:  62% (42/67)\u001b[K\rremote: Counting objects:  64% (43/67)\u001b[K\rremote: Counting objects:  65% (44/67)\u001b[K\rremote: Counting objects:  67% (45/67)\u001b[K\rremote: Counting objects:  68% (46/67)\u001b[K\rremote: Counting objects:  70% (47/67)\u001b[K\rremote: Counting objects:  71% (48/67)\u001b[K\rremote: Counting objects:  73% (49/67)\u001b[K\rremote: Counting objects:  74% (50/67)\u001b[K\rremote: Counting objects:  76% (51/67)\u001b[K\rremote: Counting objects:  77% (52/67)\u001b[K\rremote: Counting objects:  79% (53/67)\u001b[K\rremote: Counting objects:  80% (54/67)\u001b[K\rremote: Counting objects:  82% (55/67)\u001b[K\rremote: Counting objects:  83% (56/67)\u001b[K\rremote: Counting objects:  85% (57/67)\u001b[K\rremote: Counting objects:  86% (58/67)\u001b[K\rremote: Counting objects:  88% (59/67)\u001b[K\rremote: Counting objects:  89% (60/67)\u001b[K\rremote: Counting objects:  91% (61/67)\u001b[K\rremote: Counting objects:  92% (62/67)\u001b[K\rremote: Counting objects:  94% (63/67)\u001b[K\rremote: Counting objects:  95% (64/67)\u001b[K\rremote: Counting objects:  97% (65/67)\u001b[K\rremote: Counting objects:  98% (66/67)\u001b[K\rremote: Counting objects: 100% (67/67)\u001b[K\rremote: Counting objects: 100% (67/67), done.\u001b[K\n",
            "remote: Compressing objects: 100% (44/44), done.\u001b[K\n",
            "remote: Total 50338 (delta 20), reused 57 (delta 12), pack-reused 50271 (from 1)\u001b[K\n",
            "Receiving objects: 100% (50338/50338), 1.66 GiB | 60.80 MiB/s, done.\n",
            "Resolving deltas: 100% (30405/30405), done.\n",
            "Updating files: 100% (50030/50030), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/sakanaowo/PlantXViT\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd PlantXViT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgXOeJ-nsfcp",
        "outputId": "2718aeac-2779-40b0-f026-b9f5f362baa7"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/PlantXViT/PlantXViT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess from here\n"
      ],
      "metadata": {
        "id": "n96ffmC0snzD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from utils.config_loader import load_config\n",
        "config = load_config(\"configs/config.yaml\")"
      ],
      "metadata": {
        "id": "OiKYDHN9suQ9"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sz6Er4-Ss382",
        "outputId": "bf2276e2-2d4f-4b25-d577-9cdfb052f847"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'dataset': {'embrapa': {'image_size': [224, 224], 'data_dir': './data/raw/embrapa', 'label_encoder': './data/processed/embrapa_label_encoder.pkl'}, 'apple': {'image_size': [224, 224], 'data_dir': './data/raw/plant-pathology-2020-fgvc7/images', 'csv_path': './data/raw/plant-pathology-2020-fgvc7/train.csv', 'label_encoder': './data/processed/apple_label_encoder.pkl'}}, 'training': {'batch_size': 16, 'epochs': 50, 'learning_rate': 0.0001, 'optimizer': 'adam', 'loss': 'categorical_crossentropy'}, 'model': {'patch_size': 5, 'transformer_blocks': 4, 'embedding_dim': 16, 'dropout_rate': 0.1}, 'output': {'embrapa': {'save_dir': './outputs/embrapa', 'model_path': './outputs/embrapa/models/plantxvit_best.pth', 'log_dir': './outputs/embrapa/logs', 'explain_dir': './outputs/embrapa/explain'}, 'apple': {'save_dir': './outputs/apple', 'model_path': './outputs/models/apple/plantxvit_best.pth', 'log_dir': './outputs/apple/logs', 'explain_dir': './outputs/apple/explain'}}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pickle\n"
      ],
      "metadata": {
        "id": "s0g5TW62siUM"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pickle\n",
        "\n",
        "def process_split_with_check(split_dir, verbose=True):\n",
        "    image_paths = []\n",
        "    labels = []\n",
        "\n",
        "    for label_name in sorted(os.listdir(split_dir)):\n",
        "        label_path = os.path.join(split_dir, label_name)\n",
        "        if not os.path.isdir(label_path):\n",
        "            continue\n",
        "\n",
        "        valid_files = [\n",
        "            fname for fname in os.listdir(label_path)\n",
        "            if fname.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
        "        ]\n",
        "\n",
        "        # Bỏ qua class rỗng\n",
        "        if len(valid_files) == 0:\n",
        "            if verbose:\n",
        "                print(f\"⚠️ Bỏ qua class trống: {label_name}\")\n",
        "            continue\n",
        "\n",
        "        for fname in valid_files:\n",
        "            full_path = os.path.join(label_path, fname)\n",
        "            if os.path.exists(full_path):\n",
        "                image_paths.append(os.path.join(label_name, fname))\n",
        "                labels.append(label_name)\n",
        "            elif verbose:\n",
        "                print(f\"⚠️ Ảnh không tồn tại: {full_path}\")\n",
        "\n",
        "    return pd.DataFrame({'image_path': image_paths, 'label': labels})\n"
      ],
      "metadata": {
        "id": "3_NsYSAjsrJS"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Đường dẫn\n",
        "base_dir = \"./data/raw/embrapa\"\n",
        "\n",
        "# Tạo dataframe cho từng tập\n",
        "train_df = process_split_with_check(os.path.join(base_dir, \"train\"))\n",
        "val_df = process_split_with_check(os.path.join(base_dir, \"val\"))\n",
        "test_df = process_split_with_check(os.path.join(base_dir, \"test\"))\n",
        "\n",
        "# Encode nhãn\n",
        "label_encoder = LabelEncoder()\n",
        "train_df['label_idx'] = label_encoder.fit_transform(train_df['label'])\n",
        "val_df['label_idx'] = label_encoder.transform(val_df['label'])\n",
        "test_df['label_idx'] = label_encoder.transform(test_df['label'])\n",
        "\n",
        "# Lưu lại\n",
        "output_dir = \"./data/processed/embrapa\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "train_df.to_csv(os.path.join(output_dir, \"train.csv\"), index=False)\n",
        "val_df.to_csv(os.path.join(output_dir, \"val.csv\"), index=False)\n",
        "test_df.to_csv(os.path.join(output_dir, \"test.csv\"), index=False)\n",
        "\n",
        "# Lưu label encoder\n",
        "with open(os.path.join(output_dir, \"label_encoder.pkl\"), \"wb\") as f:\n",
        "    pickle.dump(label_encoder, f)\n",
        "\n",
        "print(\"✅ Đã tạo lại đầy đủ train/val/test CSV với kiểm tra ảnh.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3SAYEIx5s2V",
        "outputId": "7c2766b9-6d85-4401-9e72-68501ef4c19f"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Đã tạo lại đầy đủ train/val/test CSV với kiểm tra ảnh.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checking\n",
        "\n",
        "df = pd.read_csv(\"./data/processed/embrapa/train.csv\")\n",
        "print(\"✅ Số ảnh huấn luyện:\", len(df))\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4aUVjIcjvkoV",
        "outputId": "805bd9e5-fddb-4d94-d441-b5d0f2b1071e"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Số ảnh huấn luyện: 29607\n",
            "                                          image_path  \\\n",
            "0  Algod├úo (Cotton) - Mancha de Mirotecio (Myrot...   \n",
            "1  Algod├úo (Cotton) - Mancha de Mirotecio (Myrot...   \n",
            "2  Algod├úo (Cotton) - Mancha de Mirotecio (Myrot...   \n",
            "3  Algod├úo (Cotton) - Mancha de Mirotecio (Myrot...   \n",
            "4  Algod├úo (Cotton) - Mancha de Mirotecio (Myrot...   \n",
            "\n",
            "                                               label  label_idx  \n",
            "0  Algod├úo (Cotton) - Mancha de Mirotecio (Myrot...          0  \n",
            "1  Algod├úo (Cotton) - Mancha de Mirotecio (Myrot...          0  \n",
            "2  Algod├úo (Cotton) - Mancha de Mirotecio (Myrot...          0  \n",
            "3  Algod├úo (Cotton) - Mancha de Mirotecio (Myrot...          0  \n",
            "4  Algod├úo (Cotton) - Mancha de Mirotecio (Myrot...          0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#checking\n",
        "import os\n",
        "\n",
        "def count_valid_images(folder):\n",
        "    count = 0\n",
        "    for f in os.listdir(folder):\n",
        "        if f.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "            count += 1\n",
        "    print(count)\n",
        "    return count\n",
        "\n",
        "base_dir = \"./data/raw/embrapa/train\"\n",
        "class_stats = {}\n",
        "\n",
        "for class_name in sorted(os.listdir(base_dir)):\n",
        "    class_path = os.path.join(base_dir, class_name)\n",
        "    if os.path.isdir(class_path):\n",
        "        n = count_valid_images(class_path)\n",
        "        class_stats[class_name] = n\n",
        "\n",
        "# In các class có ít ảnh hoặc không có ảnh\n",
        "for k, v in class_stats.items():\n",
        "    if v < 5:\n",
        "        print(f\"⚠️ {k}: {v} ảnh hợp lệ\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Lx5ded5KwoJl",
        "outputId": "057873f6-a475-4892-8127-75219df4512e"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "95\n",
            "105\n",
            "1094\n",
            "157\n",
            "12\n",
            "32\n",
            "56\n",
            "244\n",
            "735\n",
            "112\n",
            "32\n",
            "70\n",
            "540\n",
            "852\n",
            "1352\n",
            "41\n",
            "26\n",
            "648\n",
            "1059\n",
            "66\n",
            "156\n",
            "12\n",
            "144\n",
            "196\n",
            "94\n",
            "41\n",
            "16\n",
            "172\n",
            "281\n",
            "97\n",
            "372\n",
            "22\n",
            "12\n",
            "389\n",
            "124\n",
            "64\n",
            "12\n",
            "84\n",
            "40\n",
            "358\n",
            "24\n",
            "49\n",
            "268\n",
            "600\n",
            "64\n",
            "384\n",
            "24\n",
            "48\n",
            "116\n",
            "83\n",
            "416\n",
            "73\n",
            "14\n",
            "14\n",
            "16\n",
            "13\n",
            "14\n",
            "60\n",
            "7\n",
            "108\n",
            "9\n",
            "94\n",
            "16\n",
            "568\n",
            "1950\n",
            "2412\n",
            "498\n",
            "11\n",
            "684\n",
            "99\n",
            "7\n",
            "19\n",
            "7\n",
            "2425\n",
            "12\n",
            "1449\n",
            "988\n",
            "198\n",
            "617\n",
            "10\n",
            "1475\n",
            "825\n",
            "798\n",
            "52\n",
            "240\n",
            "13\n",
            "236\n",
            "424\n",
            "512\n",
            "32\n",
            "381\n",
            "85\n",
            "52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "create dataset class and dataloader from here"
      ],
      "metadata": {
        "id": "6QCiJEc5trGd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "class EmbrapaDataset(Dataset):\n",
        "    def __init__(self, csv_path, root_dir, transform=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_path (str): Đường dẫn đến CSV chứa image_path, label, label_idx\n",
        "            root_dir (str): Thư mục gốc chứa các ảnh (thường là ./data/raw/embrapa/)\n",
        "            transform (callable, optional): Transform áp dụng lên ảnh\n",
        "        \"\"\"\n",
        "\n",
        "        self.df = pd.read_csv(csv_path)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        img_path = os.path.join(self.root_dir, row[\"image_path\"])\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        label = torch.tensor(int(row[\"label_idx\"]), dtype=torch.long)\n",
        "        return image, label\n"
      ],
      "metadata": {
        "id": "Nkmbj5Yitvqp"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#just checking\n",
        "import pandas as pd\n",
        "df = pd.read_csv('./data/processed/embrapa/train.csv')\n",
        "print(\"Số dòng:\", len(df))\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2dZgDFhuV9W",
        "outputId": "16154c2d-024c-4074-e5ff-d4e44c73fbe0"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Số dòng: 29607\n",
            "                                          image_path  \\\n",
            "0  Algod├úo (Cotton) - Mancha de Mirotecio (Myrot...   \n",
            "1  Algod├úo (Cotton) - Mancha de Mirotecio (Myrot...   \n",
            "2  Algod├úo (Cotton) - Mancha de Mirotecio (Myrot...   \n",
            "3  Algod├úo (Cotton) - Mancha de Mirotecio (Myrot...   \n",
            "4  Algod├úo (Cotton) - Mancha de Mirotecio (Myrot...   \n",
            "\n",
            "                                               label  label_idx  \n",
            "0  Algod├úo (Cotton) - Mancha de Mirotecio (Myrot...          0  \n",
            "1  Algod├úo (Cotton) - Mancha de Mirotecio (Myrot...          0  \n",
            "2  Algod├úo (Cotton) - Mancha de Mirotecio (Myrot...          0  \n",
            "3  Algod├úo (Cotton) - Mancha de Mirotecio (Myrot...          0  \n",
            "4  Algod├úo (Cotton) - Mancha de Mirotecio (Myrot...          0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "base_dir = \"./data/raw/embrapa/train\"\n",
        "class_folders = os.listdir(base_dir)\n",
        "print(\"Số class:\", len(class_folders))\n",
        "print(\"Một số class:\", class_folders[:5])\n",
        "\n",
        "# Lấy thử 1 ảnh từ 1 class\n",
        "for class_name in class_folders:\n",
        "    class_path = os.path.join(base_dir, class_name)\n",
        "    if os.path.isdir(class_path):\n",
        "        files = os.listdir(class_path)\n",
        "        print(f\"📂 {class_name}: {len(files)} ảnh | VD: {files[:3]}\")\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRkk9nJFuneP",
        "outputId": "0a3f3efb-9132-42b2-cb86-6932dda35da2"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Số class: 93\n",
            "Một số class: ['Milho (Corn) - Ferrugem_Branca (Tropical rust) - Cropped', 'Couve (Cabbage) - Oidio (Powdery mildew) - Cropped', 'Soja (Soybean) - Fito de cobre (Copper Phytotoxicity) - Cropped', 'Coqueiro (Coconut Tree) - Mosca Branca (Whitefly) - Cropped', 'Couve (Cabbage) - Mancha de Alternaria (Alternaria leaf spot) - Cropped']\n",
            "📂 Milho (Corn) - Ferrugem_Branca (Tropical rust) - Cropped: 568 ảnh | VD: ['fbra707.jpg', 'fbra085.jpg', 'fbra159.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Transform dùng chung cho cả 3 tập\n",
        "embrapa_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Root thư mục chứa ảnh\n",
        "image_root = \"./data/raw/embrapa/train\"\n",
        "\n",
        "# Tạo dataset\n",
        "train_dataset = EmbrapaDataset(\"./data/processed/embrapa/train.csv\", image_root, transform=embrapa_transform)\n",
        "val_dataset = EmbrapaDataset(\"./data/processed/embrapa/val.csv\", image_root, transform=embrapa_transform)\n",
        "test_dataset = EmbrapaDataset(\"./data/processed/embrapa/test.csv\", image_root, transform=embrapa_transform)\n",
        "\n",
        "# Tạo DataLoader\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16)\n"
      ],
      "metadata": {
        "id": "XcVbv7WXtyiA"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "training from here\n"
      ],
      "metadata": {
        "id": "rJmlwon_1NRp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from src.model import PlantXViT"
      ],
      "metadata": {
        "id": "m2Wk0xMZt9vF"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Load label encoder để biết số lớp\n",
        "import pickle\n",
        "with open(\"./data/processed/embrapa/label_encoder.pkl\", \"rb\") as f:\n",
        "    label_encoder = pickle.load(f)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "# Khởi tạo mô hình\n",
        "model = PlantXViT(num_classes=num_classes).to(\"cuda\")\n",
        "\n",
        "# Cấu hình optimizer, loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n"
      ],
      "metadata": {
        "id": "lC71rfL934QG"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "    for images, labels in dataloader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    return running_loss / total, correct / total\n"
      ],
      "metadata": {
        "id": "yt9vqek53__d"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    return running_loss / total, correct / total\n"
      ],
      "metadata": {
        "id": "8PX8Btvg4CeR"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, criterion, optimizer,\n",
        "                num_epochs, device, save_path=\"./outputs/models/embrapa/plantxvit_embrapa_best.pth\"):\n",
        "    best_val_loss = float(\"inf\")\n",
        "    history = {\"train_loss\": [], \"val_loss\": [], \"train_acc\": [], \"val_acc\": []}\n",
        "\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        val_loss, val_acc = evaluate(model, val_loader, criterion, device)\n",
        "\n",
        "        print(f\"Epoch [{epoch}/{num_epochs}] \"\n",
        "              f\"Train Loss: {train_loss:.4f}, Acc: {train_acc:.4f} | \"\n",
        "              f\"Val Loss: {val_loss:.4f}, Acc: {val_acc:.4f}\")\n",
        "\n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "        history[\"val_loss\"].append(val_loss)\n",
        "        history[\"train_acc\"].append(train_acc)\n",
        "        history[\"val_acc\"].append(val_acc)\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            print(\"✅ Saved best model.\")\n",
        "\n",
        "    return history\n"
      ],
      "metadata": {
        "id": "GFK3Qth94F1p"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device(\"cuda\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SL4sN6Rf69-L",
        "outputId": "9c344ecc-90ba-4659-bdaa-b60eb478cd15"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "history = train_model(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    num_epochs=50,\n",
        "    device=device,\n",
        "    save_path=\"./outputs/models/embrapa/plantxvit_embrapa_best.pth\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "7JtpCs0C4z9D",
        "outputId": "bc15abe7-20a2-4f81-86c2-a850bf279057"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-22a336458f4a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = train_model(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mval_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-82-8358906ec16e>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, num_epochs, device, save_path)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-80-2fb2a01a2070>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, dataloader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mrunning_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Handle `CustomType` automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \"\"\"\n\u001b[0;32m--> 398\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             return [\n\u001b[0m\u001b[1;32m    212\u001b[0m                 \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             return [\n\u001b[0;32m--> 212\u001b[0;31m                 \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             ]  # Backwards compatibility.\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcollate_fn_map\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0melem_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcollate_type\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_typed_storage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}